\chapter{Approach}\label{chap:approach}

% Rust has its own share of problems, but a lot of the aforementioned issues will
% be adressed using Rust in this implementation.


\section{Problem Description}\label{sec:problem}

As noted in \secref{sec:task}, the main goals include testing the integration
of Rust within Python, by implementing a counter-version to the original Python
implementation of the iterative part of the ICE algorithm, and then comparing
it with the original Python-implementation as well as the recent implementation
of the KR-algorithm in C++. It will be tested if the memory efficiacy can be
improved, also how well the parallelization using Rust works really, and how
the integration from Python to Rust works. For C/C++ there exist the Python
headers, and extensive support from Pythons package manager \verb|pip| and
common packaging tools like \verb|setuptools|. For Rust, as it turns out, the
support using Python headers is not as easy, and the support for building packages
from Pythons side is early at best. Both of this will be covered in
\secref{sec:integration} and \secref{sec:api} respectively. 

% \draft{Possible to improve memory? Testing Parallelization(?) Integration How? Describe Python to C/C++ short}



% Wolff: Jede Position im Genom hat in der Summe die gleiche anzahl an
%        interaktionen mit anderen Positionen des Genoms.

\section{Iterative Correction and Eigenvector decomposition (Algorithm)}\label{sec:ICE}

In the following the algorithm as defined in the supplementary material to
\cite{imakaev2012iterative} will be cited.

The Algorithm was proposed by Imakaev et al. 2012 \cite{imakaev2012iterative}

The goal is to obtain the the vector of biases $B_i$ and the `true' contact map
$T_{ij}$ with their relative contact probabilities. This is done by explicitly
solving the system of the following two equations:

\begin{equation} \label{eq:1}
O_{ij} = B_i B_j T_{ij}
\end{equation}
\begin{equation} \label{eq:2}
\sum^N_{i=1, |i-j|>1} T_{ij} = 1
\end{equation}

% [...] \\
% For a range of distributions, the maximum-likelihood solution for $B_i$ under
% these constraints is the solution of the above equaltion, which can be found
% by the simple iterative procedure described below. After the vector of biasesll
% is computed, the corrected map of relative contact probabilities is obtained
% by $T_{ij} = O_{ij} / (B_i B_j)$.

\eqref{eq:1} is stating, that when applying $B$ back again on our corrected
matrix $T_{ij}$, it will be the same as the original matrix $O_{ij}$ again.
\eqref{eq:2} states, that the sum over the corrected matrix, over arbitrary
elements in the upper left triangle, but only one from each column, sums up to
one. $T_{ij}$ is doubly stochastic ($\forall_j\sum^N_{i=1}T_{ij} = 1$ and
$\forall_i\sum^N_{j=1}T_{ij} = 1$), \extend{does it say that it is the same?
why is this actually valid?}


In the algorithm, this is achieved in the following way. First, $W_{ij}$, a
copy of $O_{ij}$ is created. This matrix will converge to $T_{ij}$ during the
iterative process. The elements of $B$ are initialized with $1$.

% Algorithmically, the iterative correction is implemented as follows. We start
% by creating a working copy of the matrix $O_{ij}$, denoted $W_{ij}$ as the
% iterative process gradually changes this matrix to $T_{ij}$. We initialize
% the iterative procedure by setting each element of the vector of total biases
% $B$ to 1.

\begin{equation}\label{eq:3}
    S_i = \sum_j W_{ij}
\end{equation}
\begin{equation}\label{eq:4}
    \Delta B_i = S_i / mean(S)
\end{equation}
Each iteration starts by first calculating the coverage by summing up each row
(or column, matrix is symmetric so this does not matter) (\eqref{eq:3}) and
additional biases based on this by dividing them through their own mean
(\eqref{eq:4}).

\begin{equation}\label{eq:5}
    W_{ij} = W_{ij} / \Delta B_i \Delta B_j
\end{equation}
\begin{equation}\label{eq:6}
    B_i = B_i \cdot \Delta B_i
\end{equation}
Then $W_{ij}$ is iterated by dividing by $\Delta B_i \cdot \Delta B_j$
(\eqref{eq:5}), after which $B_i$ is iterated by multiplying with the current
biases (\eqref{eq:6}). $W_{ij}$ accumulates divisions by $\Delta B_i$, just as
$B_i$ accumulates the products of $\Delta B_i$. This is repeated until the
variance of $\Delta B$ becomes negegible, at which point $W_{ij}$ has converged
to $T_{ij}$.
% We begin each iteration by calculating the coverage $S_i = \sum_j W_{ij}$.
% Next, additional biases $\Delta B_i$ are calculated by renormalizing $S_i$ to
% have the unit mean $\Delta B_i = S_i /$ mean $(S_i)$. We then divide $W_{ij}$
% by $\Delta B_i \Delta B_j$ for all $(i, j)$ and update the total vector of
% biases by multiplying by the additional biases. Iterations are repeated until
% the variance of the additional biases becomes negligible; at this point
% $W_{ij}$ has converged to $T_{ij}$.






\section{Introducing Rust}\label{sec:Rust}

\subsection{History}\label{sec:RustHistory}

Rust started out 2006 as a personal project of Graydon Hoare, a Mozilla
employee \cite{rustbegin}. Mozilla started sponsoring in 2009 \cite{rustbegin}.
The first compiler was written in OCaml, but 2011 rustc was able to compile
itself with the llvm backend \cite{rustcompile}. Starting with Rust 1.0, which
itself got released on May 15, 2015 \cite{rustversions}, there was a new stable
point version every six weeks \cite{rustversions}. Early on, Rust had frequent
breaking changes \cite{rustchanges}, recently barely anyone had breakage when
updating \cite{rustupdate}.

\subsection{Categorization}\label{sec:RustCategory}

Rust is classified as a high-level language, even though fine low-level control
is possible. This is due the high amount of high-level zero-cost abstractions.
Rust has a type system with strong guarantees, promising e.g. that all
references (pointers) are valid, or thread safety (memory access from other
threads does not result in data races / undeterminism). This is possible
through concepts such as ownership and lifetimes. Even though one can program
in an object oriented way, Rust is primarily not object-oriented. Additionally
it is imperative, procedural, generic and functional.

\subsection{Language Features}\label{sec:RustFeatures}

\textbf{Syntax:}\label{sec:syntax}
The concrete syntax seems similar to C/C++ (curly braces, function signatures),
however it is more similar to that of ML or Haskell. A particular example for
this case are type classes called ``traits'' here, similar to C++ templates but
inspired from Haskell, supporting polymorphism and generic types. Generic
parameters can be constraints, by requiring that generic type to implement a
certain Trait.

\textbf{Memory safety:}\label{sec:memsafe}
Rust is designed to be memory safe, and does not permit dangling pointers, null
pointers, data races in safe code, or usage of uninitialized variables. In case
a `null' is needed, the Option-type is provided. Thus, the compiler can
guarantee the validity of all references at compile time using its
borrow-checker.

% The system is designed to be memory safe, and it does not permit null
% pointers, dangling pointers, or data races in safe code.[30][31][32][33] Data
% values can only be initialized through a fixed set of forms, all of which
% require their inputs to be already initialized.[34] To replicate the function
% in other languages of pointers being either valid or NULL, such as in linked
% list or binary tree data structures, the Rust core library provides an option
% type, which can be used to test if a pointer has Some value or None.[31] Rust
% also introduces added syntax to manage lifetimes, and the compiler reasons
% about these through its borrow checker.

\textbf{Memory management:}\label{sec:memmanage}
Rust does not have a garbage collector, instead, the resource acquisition is
initialization (RAII) convention is used, with optional reference counting.
Resource management is deterministic with very little overhead, favoring stack
allocation without implicit boxing. References are not run time counted, as
their usage is verified at compile time. with this, memory safety can be
guaranteed, limiting possible undefined behaviour tremendously.

% Rust does not use an automated garbage collection system like those used by
% Go, Java, or the .NET Framework. Instead, memory and other resources are
% managed through the resource acquisition is initialization (RAII) convention,
% with optional reference counting. Rust provides deterministic management of
% resources, with very low overhead.[citation needed] Rust also favors stack
% allocation of values and does not perform implicit boxing. There is also a
% concept of references (using the & symbol), which do not involve run-time
% reference counting. The safety of using such pointers is verified at compile
% time by the borrow checker, preventing dangling pointers and other forms of
% undefined behavior.

\textbf{Ownership:}\label{sec:ownership}
In Rust, all values have a unique owner, and the scope of the value is the same
as the owners. Immutable references can be passed using \verb|&T|, mutable
references by \verb|&mut T|. Pass by value works by passing \verb|T|. Only
\textbf{one} mutable reference can exist at any point, or any number of
immutable ones. This is enforced at compile-time.

\textbf{Borrowing:}\label{sec:borrowing}
Borrowing results directly from the concept of ownership. As mentioned, only one mutable
borrow (reference) can happen at a time, however that borrowing variable can
further borrow it to other variables or functions. The number of immutable
borrows is unlimited, meaning there can be multiple references reading but not
modifying part of the memory. This is necessary to guarantee memory safety, as
only one mutable reference can write to it at any point in time, wherever that
is (in the code).

\textbf{Lifetimes:}\label{sec:lifetimes}
Lifetimes are the simple concept of keeping track how long each variable and
each reference is `alive', this is preventing the simple case of `variables
going out of scope' and returning a pointer to it, but can do the same in much
more complex environments. Non-Lexical-Lifetimes also work together with
borrowing, resulting in variables returning their borrow before the end of the
scope, as can be see in the first example of \secref{sec:examples}.

\textbf{Tooling:}\label{sec:tools}

The reason Rust is loved \cite{rustloved} this much is at least partly due to
tooling. This includes the dedicated package manager \verb|cargo|, the linter
\verb|rustfmt| or \verb|cargo-fix| (a subcommand that can be added later), that
format Rust code after predefined guidelines, or fix most compiler lint warnings
automatically and upgrade to newer conventions, respectively.

More information about Rust can be found
here\footnote{\url{https://www.rust-lang.org/}, accessed 2019-06-26}.




\newpage
\subsection{Examples}\label{sec:examples}

\textbf{Demonstrating Ownership and Borrowing:}

By executing \coderef{own1} the output from \outref{out1} will be returned.

\code{code_ownership.rs}{own1}

\console{output1.txt}{out1}

As the compiler is complaining, v needs a {\em mutable} borrow to modify
\verb|v|, however \verb|x| still has an {\em immutable} borrow! The borrow from
\verb|x| cannot be ended yet, because it should be printed later. As the mutable
borrow from \verb|v| could modify it in a way such that the reference \verb|x|
would be invalid (e.g. delete \verb|v|), this is a potential memory safety problem.
However it is fine to print x first, and modify \verb|v| afterwards. In
\outref{out2} can be seen what happens when printing the second element of
\verb|v| instead of \verb|x| in the last line, and printing \verb|x| before
adding the second element of \verb|v| (as shown in \coderef{own2}).

\code{code_ownership2.rs}{own2}
\console{output2.txt}{out2}

\newpage
\textbf{Demonstrating Ease of Parallelization:}

Due to the strong guarantees from the compiler, Memory Safety can be extended
to thread safety. In \coderef{par1} the function \verb|heavy_operation| is
applied to every element in the list. For this, over the list \verb|somelist|
is being iterated, and \verb|heavy_operation| mapped over by taking the values
from the map-closure - Closures are comparable with lambda-functions from
Python, in that they can take arguments and are unnamed functions. \\
\coderef{par1} and \coderef{par2} demonstrate how easy it is to turn
non-parallel code (\coderef{par1}) in parallelized code (\coderef{par2}).
The difference here being the imported \verb|rayon::prelude::*| and instead of
\verb|iter| now applying \verb|par_iter| to the original list.

\code{code_parallel1.rs}{par1}

\code{code_parallel2.rs}{par2}



\subsection{Advantages of Rust}\label{sec:RustAdvantages}

% Two parts, one, language, second, for this use-case

\textbf{In General:} As seen in \secref{sec:RustFeatures} and
\secref{sec:examples}, Rust has several high-level features ready to use,
supporting the developer tremendously. Strong compiler guarantees allow easy
parallelization and using Rust libraries without worry, since the compiler will
complain if it used wrong. In combination with semantic
versioning\footnote{\url{https://semver.org/}, accessed 2019-06-26}, this
allows adding and using dependencies without worry. The result are many small
libraries which depend upon each other, instead of few big ones. Dependencies
upon one hundred Rust libraries are not uncommon, and the strong guarantees
from the compiler enforce correct usage.

\textbf{For this project:} Even though high modularity exists, the Rust
ecosystem is comparatively young. meaning even though many libraries exist,
they are not as complete as their Python/C/C++ counterparts. Since no
implementation of CSRMatrix having the required features, even though several
existed, it was implemented again, adding the one necessary feature, and not
implementing any other. This has the advantage of being a very specific
solution, possibly faster and smaller than the general ones available.

Also, as seen in \todo{Link section results}, Parallelization can decrease
the elapsed computation time.

% The advantage of using Rust over using \verb|numpy| / \verb|scipy| from Python
% for this work might not be immediately obvious, since the CSRMatrix had to be
% implemented. We considered using the \verb|numpy| C-API for a while, but its
% too big to be actually useful for our use-case.

% The advantage here is actually much simpler: since we barely need any of the
% features provided, implementing them ourselves is not much work and gives us
% way more fine grained control as to what is actually happening.

% This includes the parallelization of some parts of the code, which might not
% have been possible if ther were some other library doing things in its own way
% (numpy using the C-API would be an example here).

% A future advantage is also the modularity of Rust code, meaning in the future
% additional external libraries (and with them, features) could easily be integrated.




\subsection{Disadvantages of Rust}\label{sec:RustDisadvantages}

% Two parts again, one, language, second, for this use-case

\textbf{In General:} General disadvantages of Rust include the young ecosystem
with slightly less diversity, or too much feature-incomplete diversity. The
steep learning curve in the beginning, needs to be mentioned, since Rusts
features cannot be selectively activated. Compared to languages like GO, Rust
has considerably higher initial compile times. Even though breakage rarely
happens \cite{rustupdate}, a new point-release happens every six weeks,
frequently introducing new features. The userbase is still growing, and many
features frequently used in other languages, such as \verb|async| or
specializations, are not available for users of the stable compiler.

\textbf{For this project:} In particular, the unavailability of a CSRMatrix
implementation with the needed features is concerning. Thus, the current
implementation does not have any more features than are needed for the current
algorithm, being only a tiny subset of the features provided by the
\verb|scipy| implementation.


\subsection{Comparing Rust and Python}\label{sec:rustvspython}

Rust and Python are two quite different programming languages, a direct
``translation'' is not possible. Both implementations are the same semantically,
however details differ. Since Rust has a much finer control of memory and the
applying of functions to data structures, some operations have been explicitly
separated while others have been combined.

Depending on the questions asked, either language may prevail. While Python
allows (seemingly) faster development cycles, it is more prone to runtime
errors and library misuse. For Rust, the compiler provides strong guarantees,
requiring more development time up front but less to fix bugs.


\subsection{Comparing Rust with C/C++}\label{sec:rustvscc++}


The following table was done with information from the benchmarksgame comparing Rust with
C\footnote{\url{https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/rust.html},
accessed 2019-06-26}, and
C++\footnote{\url{https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/rust-gpp.html},
accessed 2019-06-26}. Runtime in seconds.

\begin{table}[ht]
    \ra{1.3}
\begin{tabular}{@{}lllr@{}}
    \textbf{Speed comparison} & C & Rust & C++ \\ \midrule
    n-body & 7.49 & \textbf{5.72} & 8.18 \\
    binary-trees & 3.48 & \textbf{3.15} & 3.79 \\
    pidigits & \textbf{1.75} & \textbf{1.75} & 1.89 \\
    reverse-complement & 1.78 & 1.61 & \textbf{1.55} \\
    spectral-norm & 1.98 & \textbf{1.97} & 1.98 \\
    fannkuch-redux & \textbf{8.61} & 10.23 & 10.08 \\
    k-nucleotide & 5.01 & 5.25 & \textbf{3.76} \\
    fasta & 1.36 & 1.47 & \textbf{1.33} \\
    mandelbrot & 1.65 & 1.96 & \textbf{1.5} \\
    regex-redux & \textbf{1.46} & 2.43 & 1.82 \\ \midrule
    Fastest in: & 3/10 & 4/10 & 4/10 \\
\end{tabular}
\end{table}

Memory usages behaves alike. This means that Rust, C and C++ are at least
similar in regards to computational resource requirenments, even when
ignoing everything else.

From a developer standpoint however, Rust has consistently been the `most loved
Language` \cite{rustloved} for the last four years, whereas C and C++ both rank
considerably high in the category `dreaded` \cite{rustloved}. Reasons why Rust
may be such a loved language are listed in \secref{sec:RustAdvantages}. Due to
the barely integrated external static analysis done for C/C++-code, both C and
C++ have higher developer time needs, and are more prone to memory bugs
\cite{pronememory}.


% \todo{rewrite on abstract niveau for computer scientists}

% Rust does not have a garbage collector, but frees memory the moment it is not
% needed anymore, which it knows through the Lifetime every variable and
% reference (pointer) has. Ownership prevents you from modifying data structures
% in unintended ways, and combined with lifetimes, preventing almost all
% segfaults. Also, it runs blazingly fast, comparable to



\subsection{Integration of Rust in Python}\label{sec:integration}


\todo{interface from python to C but missing to RUST}

\todo{Answer this question later!!}

One of the main questions for this work was to find out if it is possible to
integrate Rust in Python for the HiCExplorer, and evaluate the advantages
versus disadvantages.

\todo{rewrite}

For Rust and Python to interact, there are of course several ways. Those
integrating a library written in Rust to allow them to be called from Python
will be described in depth in \secref{sec:api}.


% \todo{restructure: Introducing Rust (4.3), Advantages Rust (4.3.1), Disadvantages Rust (4.3.2), Differences Rust Python (4.3.3)}

% \todo{move integration of Rust to 4.4}

% \todo{move 'Operation' to 'Using this implementation' in 4.5}






% \newpage
\subsection{Using this implementation}\label{sec:using}

% \todo{rename: ....}

% \todo{Change Name!!}

% \subsection{Installation}\label{sec:install}

% \todo{for installing using conda add dependencies}

% \todo{Change Name!!}
% smb can be run on any Unix-based operating system (tested using ubuntu-18.04)
% with Conda, Python and common development packages installed (e.g.
% \verb!libopenssl-dev python3-dev build-essential! ...). For the installation
% itself just enter \verb|conda install -c kargf smb|.

% \textbf{For using, not building, installation of Rust is not needed.}


% \subsection{Build}\label{sec:build}

% To build the package, assuming you have conda installed, execute the following
% commands:

% \begin{verbatim}

% # first, install rust:
% curl https://sh.rustup.rs -sSf | sh -s -- -y

% # alternatively install rust with conda:
% conda install -c conda-forge rust

% # confirm install:
% cargo --version
% rustc --version

% # download repository and navigate in it
% git clone https://github.com/fkarg/HiC-rs
% cd HiC-rs

% # navigate to the rust code and compile (optional)
% cd smb
% cargo build
% cd ..

% # install missing python dependencies
% pip install -r requirements.txt

% # execute the setup.py (will also compile rust if not done yet)
% python setup.py build

% \end{verbatim}

% \todo{change pip to conda}


% \todo{update packages!!}


% % The approach usually starts with the problem definition and continues with what you have done. Try to give an intuition first and describe everything with words and then be more formal like `Let $g$ be ...'.





\subsection{Choosing the right API to call Rust from Python}\label{sec:api}

% There are three main ways to execute Rust code from Python. In the following,
% common techniques are investigated.

% \draft{versioning is not that relevant}

% One common way is rust-cpython. This library requires Rust 1.25 or higher
% (current versions are 1.33/34/35 for stable/beta/nightly respectively).
% Rust-cpython grants access to the python gil (global interpreter lock) with
% which Python code can be evaluated and Python objects modified. The resulting
% library (directly from compiled rust) can easily be imported into Python (but
% needs to be renamed). Native Rust code requires some wrapping first, as shown
% here:

% \inputminted{Rust}{code_cpython.rs}

% This kind of wrapping, though quite common and based on the Python C-API makes
% it hard to write idiomatic Code in Rust. Also, since Python is directly
% affected, the interactions with Python need to be considered while writing
% Rust-Code. In computer science one does usually not intentionally strive for
% complexity.

% Another common approach is using the pyO3-library, which started off as a fork
% of rust-cpython, but has since seen quite drastic changes. For example, its
% using requires at least Rust version ‘1.30.0-nightly 2018-08-18’ (or, in the
% newest version, ‘1.34.0-nightly 2019-02-06’). This is due to the usage of
% unstable features, most of which have recently been able to be promoted to
% stable. Unstable features are only available in the nightly toolchain.  Still
% missing is Specialisation, which has at the time of writing still a long way to
% go.  The library would also result in an easily importable (needs to be renamed
% first, still) cdylib (same as rust-cpython). The still intermingled way of
% writing the interface (certainly better but not by much compared to
% rust-cpython) as well as the dependency on unstable nightly rust versions led
% to the decision of not using it either.

% The third way, that is actually been promoted in the official Rust docs, is to
% generate a dylib and import that in python. No renaming necessary, but the
% communication between Rust and Python is a bit more low-level. The main wrapper
% is on the side of Python, transforming Arguments to Pointers and
% C-Representations, whilst the Rust part needs to conform to C-practices, which
% includes receiving a list by getting a pointer to the first element and the
% length of it. Other than that, the Rust code has additional
% \verb!\#[no_mangle]! and \verb!\#[repr(C)]!  (procedural) macros, preventing
% the compiler to mangle (renaming of functions) and guaranteeing the
% representation in the memory layout to be as it would be in C. Since like this
% neither language depends on something only internal (or combinatorial), and
% both just depend upon the ‘common, unchanging’ C-interface, this seems to be
% the preferred way.

% \draft{include a nice comparison table}

% \newpage
\section{General Approach}\label{sec:approach}

% \todo{Introduce main approach}

% \draft{Steps: read papers, test communication between Python and Rust (API), implementing CSRMatrix, implementing algorithm, fixing bugs (in-memory), making buildable (milksnake, conda), further bug fixing, some testing, building test-suite and a lot of bugfixing, reading papers again, starting to write stuff down.}


% \subsection{Beginning}

% \todo{Rewrite to passive voice}

% Having read the provided papers (\cite{imakaev2012iterative},
% \cite{lieberman2009comprehensive} and \cite{wingett2015hicup}) I started
% looking in the Python-implementation. First things first I started testing the
% feasability of communicating between Rust and Python. The only available way
% for this is the raw C-API both adhere to.

% \subsection{Feasability Testing}

% \todo{Rewrite to passive voice}

% Having succeded in calling functions in Rust, and passing the arguments
% correctly, I started to look in the Python-implementation again. Since in
% python \verb|numpy| and \verb|scipy| were used quite extensively (especially
% the Compressed Sparse Row Matrix from \verb|scipy| and available operations
% through \verb|numpy|) and there was no library available providing
% functionality similar enough, I implemented the minimal version of a CSRMatrix
% that would be needed, and tested its functionality.


% \subsection{Implementation of the algorithm}

% \extend{Answer: could I call numpy from rust}

% \todo{Rewrite to passive voice}

% The initial translation from Python to rust happened more or less on a
% line-by-line basis, as much as this was possible. Seeing the
% Python-implementation section-wise as a comment I started out with a comparably
% naive translation from Python to Rust. As I did not have
% \verb|numpy|/\verb|scipy| available, specific operations had to be done
% differently, and I needed to care a lot more about the memory (of the
% variables, also their availability) than the Python-implementation did.


% \subsection{Testing and Bugfixing}

% \todo{Rewrite to passive voice}

% \draft{give examples for common bugs}

% Having succeded at convincing the compiler, I wanted to test my implementation.
% The compiler in Rust is quite capable, reducing common bugs tremendously.
% My knowledge about Rust not being on the expert-level, I made the error of not
% writing back the changes made to the matrix in the matrix (more specifically,
% the part that should have done that was being handed a immutable matrix). This
% and some smaller bugs got solved easily, so I set up a small testing
% environment, even calling from python.


% \subsection{Idiomatic Rust}

% \todo{Rewrite to passive voice}

% While gradually transforming the naive Python-translation to idiomatic Rust, at
% some point results ended up being \verb|NaN| pretty fast. A while of
% debugging later, I reduced it to the following situation:

% \draft{exclude mention of debugging}

% \inputminted{Rust}{code_infsum1.rs}

% Here the output was still ``sum: 1'' and ``sum: 0''. One iteration later however, all the elements have only been multiplied with some factors, their product being \verb|0.16|.

% \inputminted{Rust}{code_infsum2.rs}

% The expected output here would be ``sum: 0.16'' and ``sum: 0'', or something
% around that. However, the actual results were ``sum: 0.4'' and ``sum: inf''. As
% it turns out, the factor they have been subject to was indeed \verb|0.16|,
% however it was \verb|0.16| with high fraction values. This means that summation
% of \verb|0.16| and \verb|0.0| (the zero also having high fraction) is being
% sufficiently inaccurate to not be accurately represented by floating point
% values. With this happening multiple times, it was unavoidable.

% The same happened with the summation of the innocious-looking \verb|0.0|. They
% had high fractions from the original multiplication by
% \verb|0.160000000000003|, their continued summation resulting in an overflow.
% This new number just happens to be one of the representations of \verb|inf|.


% \subsection{Packaging}

% \todo{Rewrite to passive voice}

% Next was the Packaging of my code. As my work should be used from within the
% HiCExplorer, My part is supposed to be available as a python-package. The \draft{only
% real} python dependcy (apart from those required for packages) ended up being
% milksnake, itself a helper for compiling the rust part of my package.

% The conda-part was not as easy though, as milksnake was not resolvable there. I
% ended up porting \verb|milksnake| as a conda package. This turned out to be a
% nontrivial task, as \verb|conda skeleton pypi milksnake| created a package
% conda could not build, the issue here being that milksnake was only provided as
% a \verb|*.zip| file and conda had hardcoded the format \verb|*.tar.gz|.

% Additionally I set up a buildserver, adding some tests and fixing smaller bugs.


% \subsection{Parallelizing}

% \todo{Rewrite to passive voice}

% Nearing the end of my work, I set up ways to test and compare my implementation
% with the other. One of the last things I did was adding Parallelization.

% \todo{add: compare parallelization in C++ and Python, accessing memory, why it is possible to easily add this, ...}


% % \subsection{Encoundered Problems}\label{sec:problems}
% %
% % \extend{add encountered Problem: Packages, milksnake, conda, ...}
% %
% % \extend{add encountered Problem: small memory bug in rust (actually mut-changing the matrix)}
% %
% % \extend{add encountered Problem: weird bug regarding nans/infs}
% %
% % \extend{add encountered Problem: bug regarding termination (?)}


% \todo{look for better rust presenter in latex}

% \todo{add the integration of travis more}


\todo{biggest points: Python to rust and how it worked, give code examples but not too much}
\todo{presentation: 1/3 für jeden, 1/3 für betreuer + vom fach, 1/3 ich bin experte}
\todo{Link to github repository}
\todo{Tag der abgabe: Github aufräumen und Dokumentieren}
